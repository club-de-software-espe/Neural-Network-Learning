# Supervised Learning and optimizers

When we talk about Supervised Learning, we refer to a process in which we give our neural network a set of input parameters for which we know the correct label, then we measure the errors in the output of the nn and the known result to finally adjust the weights of the input connections and expect for an improvement.

## Errors

We can represent the error in different ways, but the one that is commonly used is the Mean Square Error: _MSE = 1&frasl;2  (y<sub>known</sub> - y<sub>guess</sub>)<sup>2</sup>_ (for this particular case). You can go more in depth [here](https://en.wikipedia.org/wiki/Mean_squared_error).

For the first perceptron example, to keep things simple we can put the error as:  _err = y<sub>known</sub> - y<sub>guess</sub>_

Why? Well because we can see all possible outcomes of the errors in this example, like so:

| Desired | Guess | Error |
|---------|-------|-------|
| -1 | -1 | 0 |
| -1 | +1 | -2 |
| +1 | -1 | +2 |
| +1 | +1 | 0 |

## Optimizing and adjusting weights

Mainly our goal with the training is to optimize this values (_weights_),so the output becomes the expected one, we can think about this as adding a variation to the previous values, like this: _W<sub>n+1</sub> = W<sub>n</sub> + &Delta;W<sub>n</sub>_ now we have to think in a way to calculate this _&Delta;W<sub>n</sub>_ for all the weights in the perceptron.

## Gradient Descent

In this example, we are going to use a simplified version of the original method, that you can find [here](https://en.wikipedia.org/wiki/Gradient_descent). The main process to calculate &Delta;W<sub>n</sub> is to multiply the error by the input, so the direction of the new output changes towards the direction of the error, this may be a bit confusing at first, but for the sake of simplicity we are going to stablish that process in this way: _&Delta;W<sub>n</sub> = err * X<sub>n</sub>_ and _err_ is defined as: _y<sub>known</sub> - y<sub>guess</sub>_.

But here comes something interesting, we need to know how much are we changing direction towards the error, mainly because if we change it too much, it is possible we overshoot the target and start getting wrong answers again, but in the other direction, to solve this problem we introduce a variable called _learning rate_ which controls the amount we move in that particular direction, now our formula goes like this: _&Delta;W<sub>n</sub> = err * X<sub>n</sub>*Lr_ where _err_ is defined as: _y<sub>known</sub> - y<sub>guess</sub>_ and _Lr &in; ]0, 1]_

[next](/docs/eng/1.perceptron/3.refined_perceptron.md)